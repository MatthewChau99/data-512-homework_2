{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from src.data_query import request_pageinfo_per_article, request_ores_score_per_article\n",
    "from src.data_process import merge_wiki_page_and_population\n",
    "from src.global_constants import GlobalConstants\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "We would take in two datasets: <br>\n",
    "1. **politicians by country** contains the politicians, their wiki page links, as well as their origin country.\n",
    "2. **population by country** contains each country's population as well as their region in a hierarchical manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_pages_df = pd.read_csv('politicians_by_country_SEPT.2022.csv')\n",
    "\n",
    "populations_df = pd.read_csv('population_by_country_2022.csv')\n",
    "\n",
    "articles = wiki_pages_df['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making requests\n",
    "\n",
    "For each of the article in **politicians by country** dataset, we request the page info as well as the ORES predictions. We store the page info in `info_json` and ORES predictions in `ores_json`. The `global_constants` variable is created for storing all the constants that could be referred to in `src/global_constants.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:59<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "global_constants = GlobalConstants(wiki_pages_df)\n",
    "info_json = {}\n",
    "ores_json = {}\n",
    "\n",
    "for article in tqdm(articles):\n",
    "    info = request_pageinfo_per_article(article_title=article, gc=global_constants)\n",
    "    article_revid = global_constants.ores_constants.ARTICLE_REVISIONS[article]\n",
    "    ores = request_ores_score_per_article(article_revid=article_revid, gc=global_constants)\n",
    "\n",
    "    if info is not None:\n",
    "        info_json.update(info)\n",
    "    \n",
    "    if ores is not None:\n",
    "        ores_json.update(ores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the JSON files in `/data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(os.path.join(global_constants.project_root, 'data')):\n",
    "#     os.mkdir('data')\n",
    "\n",
    "# with open(os.path.join(global_constants.project_root, \"data\", \"info.json\"), \"w\") as f:\n",
    "#     json.dump(info_json, f, indent=4)\n",
    "\n",
    "# with open(os.path.join(global_constants.project_root, \"data\", \"ores.json\"), \"w\") as f:\n",
    "#     json.dump(ores_json, f, indent=4)\n",
    "\n",
    "# with open(os.path.join(global_constants.project_root, 'data', 'error_files.txt'), \"w\") as f:\n",
    "#     for error_file in global_constants.error_files:\n",
    "#         f.write(error_file + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from JSON files\n",
    "\n",
    "We now read the JSON files containing the page infos and ORES predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(global_constants.project_root, \"data\", \"info.json\"), \"r\") as f:\n",
    "    info_json = json.load(f)\n",
    "\n",
    "with open(os.path.join(global_constants.project_root, \"data\", \"ores.json\"), \"r\") as f:\n",
    "    ores_json = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging into a dataframe\n",
    "`merge_wiki_page_and_population` combines the politicians, their countries, and article quality, and so on into a structured table from their original JSON files. It also outputs countries with no matching articles in `data/wp_countries-no_match.txt`. It can be found in `src/data_process.py` for more information. <br>\n",
    "We can output the merged df to `/data/wp_politicians_by_country.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 4062/7526 [00:02<00:01, 2081.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred during processing Bak Jungyang. 'Korean'\n",
      "Error occurred during processing Kim Gap-sun. 'Korean'\n",
      "Error occurred during processing Bak Gyusu. 'Korean'\n",
      "Error occurred during processing Bak Jeongyang. 'Korean'\n",
      "Error occurred during processing Chang Deok-soo. 'Korean'\n",
      "Error occurred during processing Cho Bong-am. 'Korean'\n",
      "Error occurred during processing Cho Man-sik. 'Korean'\n",
      "Error occurred during processing Choe Bu. 'Korean'\n",
      "Error occurred during processing Choe Yun-ui. 'Korean'\n",
      "Error occurred during processing Chough Pyung-ok. 'Korean'\n",
      "Error occurred during processing Gwon Sang-ha. 'Korean'\n",
      "Error occurred during processing Han Eum. 'Korean'\n",
      "Error occurred during processing Heo Jeok. 'Korean'\n",
      "Error occurred during processing Hong Jung-wook. 'Korean'\n",
      "Error occurred during processing Hong U-won. 'Korean'\n",
      "Error occurred during processing Hwang Gi-cheon. 'Korean'\n",
      "Error occurred during processing Isabu. 'Korean'\n",
      "Error occurred during processing Jang Hyeongwang. 'Korean'\n",
      "Error occurred during processing Jeong Cheol. 'Korean'\n",
      "Error occurred during processing Jeong Hyeon-mo. 'Korean'\n",
      "Error occurred during processing Jeong Nan-jeong. 'Korean'\n",
      "Error occurred during processing Jo So-ang. 'Korean'\n",
      "Error occurred during processing Kim Gu. 'Korean'\n",
      "Error occurred during processing Kim Kyu-sik. 'Korean'\n",
      "Error occurred during processing Kim Man-jung. 'Korean'\n",
      "Error occurred during processing Kim Ok-gyun. 'Korean'\n",
      "Error occurred during processing Kim Sung-joo (politician, born 1964). 'Korean'\n",
      "Error occurred during processing Kim Yuk. 'Korean'\n",
      "Error occurred during processing Lee Hoe-yeong. 'Korean'\n",
      "Error occurred during processing Lee Kyu-wan. 'Korean'\n",
      "Error occurred during processing Lim Heon-yong. 'Korean'\n",
      "Error occurred during processing Min Won-sik. 'Korean'\n",
      "Error occurred during processing Min Yeong-chan. 'Korean'\n",
      "Error occurred during processing Myeongnim Dap-bu. 'Korean'\n",
      "Error occurred during processing No Choe. 'Korean'\n",
      "Error occurred during processing No In. 'Korean'\n",
      "Error occurred during processing Oh Se-jung. 'Korean'\n",
      "Error occurred during processing Ok Kwan-bin. 'Korean'\n",
      "Error occurred during processing Park Eun-sik. 'Korean'\n",
      "Error occurred during processing Park Won-jong. 'Korean'\n",
      "Error occurred during processing Sam of Gojoseon. 'Korean'\n",
      "Error occurred during processing Seo Jae-chang. 'Korean'\n",
      "Error occurred during processing Seo Yu-gu. 'Korean'\n",
      "Error occurred during processing Shim Soon-taek. 'Korean'\n",
      "Error occurred during processing Shin Gyu-sik. 'Korean'\n",
      "Error occurred during processing Soh Jaipil. 'Korean'\n",
      "Error occurred during processing Song Byeong-jun. 'Korean'\n",
      "Error occurred during processing Song Ikpil. 'Korean'\n",
      "Error occurred during processing Song In. 'Korean'\n",
      "Error occurred during processing Song Jin-woo (journalist). 'Korean'\n",
      "Error occurred during processing Ye Wanyong. 'Korean'\n",
      "Error occurred during processing Yeom Dong-jin. 'Korean'\n",
      "Error occurred during processing Yeon Namsan. 'Korean'\n",
      "Error occurred during processing Yi Dong-hwi. 'Korean'\n",
      "Error occurred during processing Yi Gwangsu. 'Korean'\n",
      "Error occurred during processing Yi Ja-gyeom. 'Korean'\n",
      "Error occurred during processing Yi Jehyeon. 'Korean'\n",
      "Error occurred during processing Yi Ryang. 'Korean'\n",
      "Error occurred during processing Yi Si-yeong. 'Korean'\n",
      "Error occurred during processing Yu Chin-san. 'Korean'\n",
      "Error occurred during processing Yu Kil-chun. 'Korean'\n",
      "Error occurred during processing Yu Sun-jeong. 'Korean'\n",
      "Error occurred during processing Yun Chi-ho. 'Korean'\n",
      "Error occurred during processing Yun Chi-oh. 'Korean'\n",
      "Error occurred during processing Yun Chi-wang. 'Korean'\n",
      "Error occurred during processing Yun Doo-su. 'Korean'\n",
      "Error occurred during processing Yun Im. 'Korean'\n",
      "Error occurred during processing Yun Ung-nyeol. 'Korean'\n",
      "Error occurred during processing Yun Won-hyeong. 'Korean'\n",
      "Error occurred during processing Yun Yeong-ryeol. 'Korean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7526/7526 [00:04<00:00, 1779.12it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_wiki_page_and_population(wiki_pages_df=wiki_pages_df, pop_df=populations_df, info_dict=info_json, ores_dict=ores_json, gc=global_constants)\n",
    "merged_df.to_csv(os.path.join(global_constants.project_root, 'data', 'wp_politicians_by_country.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>continent</th>\n",
       "      <th>population</th>\n",
       "      <th>article_title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "      <th>region_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>41.1</td>\n",
       "      <td>Shahjahan Noori</td>\n",
       "      <td>1099689043</td>\n",
       "      <td>GA</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>41.1</td>\n",
       "      <td>Abdul Ghafar Lakanwal</td>\n",
       "      <td>943562276</td>\n",
       "      <td>Start</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>41.1</td>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>852404094</td>\n",
       "      <td>Start</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>41.1</td>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>1095102390</td>\n",
       "      <td>B</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>41.1</td>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>1104998382</td>\n",
       "      <td>Start</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country      region continent  population          article_title  \\\n",
       "0  Afghanistan  SOUTH ASIA      ASIA        41.1        Shahjahan Noori   \n",
       "0  Afghanistan  SOUTH ASIA      ASIA        41.1  Abdul Ghafar Lakanwal   \n",
       "0  Afghanistan  SOUTH ASIA      ASIA        41.1         Majah Ha Adrif   \n",
       "0  Afghanistan  SOUTH ASIA      ASIA        41.1      Haroon al-Afghani   \n",
       "0  Afghanistan  SOUTH ASIA      ASIA        41.1            Tayyab Agha   \n",
       "\n",
       "   revision_id article_quality  region_population  \n",
       "0   1099689043              GA             2008.0  \n",
       "0    943562276           Start             2008.0  \n",
       "0    852404094           Start             2008.0  \n",
       "0   1095102390               B             2008.0  \n",
       "0   1104998382           Start             2008.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "For this analysis, we calculate **total-articles-per-population** and **high-quality-articles-per-population** for both country by country and regional basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we filter all the high quality articles into `good_articles_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_articles_df = merged_df.loc[(merged_df['article_quality'] == \"GA\") | (merged_df['article_quality'] == 'SA')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total articles per population\n",
    "\n",
    "For regular articles, we count the number of articles on country and regional basis, and divide their corresponding populations. If population is $0$, they would be filled with `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['country_article_count'] = merged_df.groupby('country')['article_title'].transform('count')\n",
    "merged_df['region_article_count'] = merged_df.groupby('region')['article_title'].transform('count')\n",
    "merged_df['articles_per_pop_country'] = merged_df.apply(lambda x: (x['country_article_count'] / x['population']) if x['population'] else np.nan, axis=1)\n",
    "merged_df['articles_per_pop_region'] = merged_df.apply(lambda x: x['region_article_count'] / x['region_population'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grouped dataframe is saved in `data/clean_data/tapp.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/t_yjgylx77s8pm8k27dxwr9m0000gn/T/ipykernel_7181/4127337365.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  tapp_df = merged_df.groupby(['region', 'country'])['country_article_count', 'region_article_count', 'articles_per_pop_country', 'articles_per_pop_region'].agg('first')\n"
     ]
    }
   ],
   "source": [
    "tapp_df = merged_df.groupby(['region', 'country'])['country_article_count', 'region_article_count', 'articles_per_pop_country', 'articles_per_pop_region'].agg('first')\n",
    "tapp_df.to_csv(os.path.join(global_constants.project_root, 'data', 'clean_data', 'tapp.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High quality articles per population\n",
    "\n",
    "Next, we count the proportion of the high quality articles. The steps are the same with above except only high quality articles are taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_articles_df['qual_country_article_count'] = good_articles_df.groupby('country')['article_title'].transform('count')\n",
    "good_articles_df['qual_region_article_count'] = good_articles_df.groupby('region')['article_title'].transform('count')\n",
    "good_articles_df['qual_articles_per_pop_country'] = good_articles_df.apply(lambda x: (x['qual_country_article_count'] / x['population']) if x['population'] else np.nan, axis=1)\n",
    "good_articles_df['qual_articles_per_pop_region'] = good_articles_df.apply(lambda x: x['qual_region_article_count'] / x['region_population'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/t_yjgylx77s8pm8k27dxwr9m0000gn/T/ipykernel_7181/2785231095.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  qapp_df = good_articles_df.groupby(['region', 'country'])['qual_country_article_count', 'qual_region_article_count', 'qual_articles_per_pop_country', 'qual_articles_per_pop_region'].agg('first')\n"
     ]
    }
   ],
   "source": [
    "qapp_df = good_articles_df.groupby(['region', 'country'])['qual_country_article_count', 'qual_region_article_count', 'qual_articles_per_pop_country', 'qual_articles_per_pop_region'].agg('first')\n",
    "qapp_df.to_csv(os.path.join(global_constants.project_root, 'data', 'clean_data', 'qapp.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating results tables\n",
    "We then generate six tables for analysis.\n",
    "\n",
    "### Top 10 countries by coverage\n",
    "The 10 countries with the highest total articles per capita (in descending order) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df1 = tapp_df.reset_index().sort_values('articles_per_pop_country', ascending=False).reset_index().loc[:10, ['country', 'articles_per_pop_country']]\n",
    "# result_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 10 countries by coverage\n",
    "The 10 countries with the lowest total articles per capita (in ascending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df2 = tapp_df.reset_index().sort_values('articles_per_pop_country').reset_index().loc[:10, ['country', 'articles_per_pop_country']]\n",
    "# result_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 countries by high quality\n",
    "The 10 countries with the highest high quality articles per capita (in descending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df3 = qapp_df.reset_index().sort_values('qual_articles_per_pop_country', ascending=False).reset_index().loc[:10, ['country', 'qual_articles_per_pop_country']]\n",
    "# result_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 10 countries by high quality\n",
    "The 10 countries with the lowest high quality articles per capita (in ascending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df4 = qapp_df.reset_index().sort_values('qual_articles_per_pop_country').reset_index().loc[:10, ['country', 'qual_articles_per_pop_country']]\n",
    "# result_df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic regions by total coverage\n",
    "A rank ordered list of geographic regions (in descending order) by total articles per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>articles_per_pop_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>5.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>5.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bosnia-Herzegovina</td>\n",
       "      <td>5.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>5.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greece</td>\n",
       "      <td>5.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Japan</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Korea, South</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Mongolia</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                country  articles_per_pop_region\n",
       "0               Albania                 5.821192\n",
       "1               Andorra                 5.821192\n",
       "2    Bosnia-Herzegovina                 5.821192\n",
       "3               Croatia                 5.821192\n",
       "4                Greece                 5.821192\n",
       "..                  ...                      ...\n",
       "179               Japan                 0.145161\n",
       "180        Korea, North                 0.145161\n",
       "181        Korea, South                 0.145161\n",
       "182            Mongolia                 0.145161\n",
       "183              Taiwan                 0.145161\n",
       "\n",
       "[184 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df5 = tapp_df.reset_index().sort_values('articles_per_pop_region', ascending=False).reset_index()[['country', 'articles_per_pop_region']]\n",
    "result_df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic regions by high quality coverage\n",
    "Rank ordered list of geographic regions (in descending order) by high quality articles per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>qual_articles_per_pop_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cuba</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haiti</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>0.165563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0.165563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Iran</td>\n",
       "      <td>0.009960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>0.009960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Japan</td>\n",
       "      <td>0.009558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>0.009558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Korea, South</td>\n",
       "      <td>0.009558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               country  qual_articles_per_pop_region\n",
       "0                 Cuba                      0.181818\n",
       "1                Haiti                      0.181818\n",
       "2   Dominican Republic                      0.181818\n",
       "3             Portugal                      0.165563\n",
       "4              Albania                      0.165563\n",
       "..                 ...                           ...\n",
       "84                Iran                      0.009960\n",
       "85               Nepal                      0.009960\n",
       "86               Japan                      0.009558\n",
       "87        Korea, North                      0.009558\n",
       "88        Korea, South                      0.009558\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df6 = qapp_df.reset_index().sort_values('qual_articles_per_pop_region', ascending=False).reset_index()[['country', 'qual_articles_per_pop_region']]\n",
    "result_df6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
